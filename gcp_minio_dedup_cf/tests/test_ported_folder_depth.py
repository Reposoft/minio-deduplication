import pytest
from unittest.mock import MagicMock, call
import io
import os

# Assuming project structure allows these imports
from gcp_minio_dedup_cf.gcs_utils import GCSUtil
from gcp_minio_dedup_cf import core_logic
from gcp_minio_dedup_cf import metadata_utils

@pytest.fixture
def mock_gcs_util(mocker):
    """Provides a mocked GCSUtil instance."""
    mocked_gcs_util_instance = mocker.MagicMock(spec=GCSUtil)
    mocked_gcs_util_instance.get_object_stream_and_metadata = mocker.MagicMock()
    mocked_gcs_util_instance.stat_object = mocker.MagicMock()
    mocked_gcs_util_instance.copy_object = mocker.MagicMock()
    mocked_gcs_util_instance.delete_object = mocker.MagicMock()
    return mocked_gcs_util_instance

# Parameterized test cases
# expected_prefix_in_archive is not directly used to construct the final path in the test logic,
# as construct_destination_path will derive it. It's here for clarity of the scenario.
test_scenarios = [
    # Scenario 1: preserved_depth = 0 (default behavior)
    ("uploads/data/file1.txt", 0, ""),
    # Scenario 2: preserved_depth = 1
    ("level1/level2/file.txt", 1, "level1/"),
    # Scenario 3: preserved_depth = 2
    ("level1/level2/file.txt", 2, "level1/level2/"),
    # Scenario 4: preserved_depth greater than actual depth
    ("level1/file.txt", 3, "level1/"),
    # Scenario 5: original_key is just a filename
    ("file_at_root.dat", 1, ""),
    # Scenario 6: original_key with leading slash
    ("/level1/level2/file.txt", 1, "level1/"),
    # Additional scenario: original_key is a directory path itself (ends with /)
    ("level1/level2/", 1, "level1/"),
    # Additional scenario: preserved_depth is 0 but path has levels
    ("level1/level2/another.doc", 0, ""),
]

@pytest.mark.parametrize(
    "original_key, preserved_depth, expected_prefix_in_archive_comment", test_scenarios
)
def test_folder_depth_preservation(
    mock_gcs_util, original_key, preserved_depth, expected_prefix_in_archive_comment
):
    """
    Tests that copy_object is called with the correct dest_blob_name
    based on the preserved_depth.
    """
    write_bucket = "test_write_bucket"
    read_bucket = "test_read_bucket"
    file_content = b"content for folder depth test"
    # Ensure original_key for GCS interaction uses '/'
    gcs_original_key = original_key.replace(os.sep, '/')


    # Mock GCS interactions
    # The actual metadata content doesn't critically affect path construction for this test,
    # but it's needed for prepare_new_metadata.
    original_gcs_metadata = {'Content-Type': 'text/testing_depth'}
    mock_gcs_util.get_object_stream_and_metadata.return_value = (
        io.BytesIO(file_content), original_gcs_metadata
    )
    mock_gcs_util.stat_object.return_value = None # Simulate new file, archive miss

    # Calculate expected values using core_logic
    sha256_hash = core_logic.calculate_sha256(io.BytesIO(file_content))
    extension = core_logic.get_original_extension(gcs_original_key)
    
    # This is the key value to check: the destination path generated by the logic
    expected_dest_blob_name = core_logic.construct_destination_path(
        original_path=gcs_original_key, # Use the GCS-style key
        sha256_hash=sha256_hash,
        original_extension=extension,
        preserved_depth=preserved_depth
    )
    # Ensure the expected_dest_blob_name uses GCS separators for assertion
    expected_dest_blob_name = expected_dest_blob_name.replace(os.sep, '/')

    # Prepare expected metadata for the archive object
    expected_archive_metadata = metadata_utils.prepare_new_metadata(
        original_object_key=gcs_original_key,
        original_object_metadata=original_gcs_metadata,
        existing_archive_object_metadata=None
    )

    # --- Simulate conceptual main_handler logic ---
    # Actual calls to GCSUtil methods that would occur in the handler
    mock_gcs_util.get_object_stream_and_metadata(write_bucket, gcs_original_key)
    mock_gcs_util.stat_object(read_bucket, expected_dest_blob_name) # Check against the expected path
    mock_gcs_util.copy_object(
        source_bucket_name=write_bucket,
        source_blob_name=gcs_original_key,
        dest_bucket_name=read_bucket,
        dest_blob_name=expected_dest_blob_name, # This is the critical assertion point
        new_metadata=expected_archive_metadata
    )
    mock_gcs_util.delete_object(write_bucket, gcs_original_key)

    # --- Assertions ---
    # Crucial assertion: copy_object was called with the correctly constructed dest_blob_name
    mock_gcs_util.copy_object.assert_called_once_with(
        write_bucket,
        gcs_original_key,
        read_bucket,
        expected_dest_blob_name, # Verifies the path construction
        new_metadata=expected_archive_metadata
    )

    # Verify other calls
    mock_gcs_util.get_object_stream_and_metadata.assert_called_once_with(write_bucket, gcs_original_key)
    mock_gcs_util.stat_object.assert_called_once_with(read_bucket, expected_dest_blob_name)
    mock_gcs_util.delete_object.assert_called_once_with(write_bucket, gcs_original_key)

```
